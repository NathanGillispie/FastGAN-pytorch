{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"NathanGAN_train.ipynb","provenance":[{"file_id":"https://github.com/jeffheaton/present/blob/master/youtube/gan/colab_gan_train.ipynb","timestamp":1639551494585}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"_9qbVplkZYjp"},"source":["# FastGAN-pytorch (NathanGAN2) training notebook for use with Google Colab\n","\n","Copyright 2021 by Nathan Gillispie, [released under GNU General Public License v3.0](https://github.com/NathanGillispie/FastGAN-pytorch/blob/main/LICENSE)\n","\n","Originally began from [Jeff Heaton's google colab file](https://github.com/jeffheaton/present/blob/master/youtube/gan/colab_gan_train.ipynb) but changed enough to become a separate work. Thanks Jeff.\n","\n"," - 1024x1024 Tesla K80 = 2.4517 it/s = .4079 s/it\n"]},{"cell_type":"code","metadata":{"id":"iPrGcTX8c7E-","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640925701467,"user_tz":300,"elapsed":549,"user":{"displayName":"Nathan Gillispie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYSIpNn8k5Q-u7HpTEhznYRNwHh-6Zpu7mFM3Gaw=s64","userId":"04712707515516063127"}},"outputId":"085d57d3-eb11-4a5e-864d-ba62e5bb9369"},"source":["!nvidia-smi"],"execution_count":25,"outputs":[{"output_type":"stream","name":"stdout","text":["Fri Dec 31 04:41:44 2021       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   49C    P8    27W / 149W |      0MiB / 11441MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"markdown","metadata":{"id":"wzWrFN_tGV-Y"},"source":["## Set up the environment\n","\n","G-Drive is used to save network models as well as recorded images."]},{"cell_type":"code","metadata":{"id":"uxs1j1bk_fwj","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1640925715418,"user_tz":300,"elapsed":3817,"user":{"displayName":"Nathan Gillispie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYSIpNn8k5Q-u7HpTEhznYRNwHh-6Zpu7mFM3Gaw=s64","userId":"04712707515516063127"}},"outputId":"55a23878-f21c-4732-952c-1a53978b0930"},"source":["try:\n","    from google.colab import drive\n","    drive.mount('/content/drive', force_remount=True)\n","    COLAB = True\n","    print(\"Note: using Google CoLab\")\n","except:\n","    print(\"Note: not using Google CoLab\")\n","    COLAB = False"],"execution_count":26,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","Note: using Google CoLab\n"]}]},{"cell_type":"markdown","source":["My version of FastGAN is not necessarily better although I prefer my repo and the FastGAN needs to be placed here anyways."],"metadata":{"id":"NLC0mOXJWD84"}},{"cell_type":"code","source":["!git clone https://github.com/NathanGillispie/FastGAN-pytorch"],"metadata":{"id":"AGAhJ8S4Rp1f"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Optionally check dependency versions. Google has the tendency to change their packages frequently and it might help to make sure all the required ones are there. This notebook could break in a matter of months so if you are accessing this after 2021 beware, I strongly recommend checking packages if training doesn't work.\n"],"metadata":{"id":"fAA3jM2uU3fp"}},{"cell_type":"code","source":["!pip show tqdm\n","!pip show scipy\n","!pip show scikit-image\n","!pip show ipdb\n","!pip show pandas\n","!pip show lmdb\n","!pip show opencv-python"],"metadata":{"id":"4kwV5SgVZxKl"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This package is not included in the default runtime so it needs to be installed."],"metadata":{"id":"DrGQFxt5vrZi"}},{"cell_type":"code","source":["!pip install ipdb==0.13.4"],"metadata":{"id":"ssfJcDygaNZm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Use this general framework for downgrading packages (although for panda as of today this is an upgrade) if and when google changes it's packages. Use the requirements.txt file as a guide."],"metadata":{"id":"-Ds6ZoHdv0sC"}},{"cell_type":"code","metadata":{"id":"uNqsi6VWAlWo"},"source":["# Only required if downgrading\n","!pip uninstall pandas -y\n","!pip install pandas==1.2.1"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Check dataset and cd into FastGAN"],"metadata":{"id":"GU8cgTPjUhXu"}},{"cell_type":"markdown","source":["ensure you change the location of your dataset in code "],"metadata":{"id":"Ja12nHX44qJk"}},{"cell_type":"code","metadata":{"id":"LGdFfTSXBBr5","executionInfo":{"status":"ok","timestamp":1640920960228,"user_tz":300,"elapsed":783,"user":{"displayName":"Nathan Gillispie","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GiYSIpNn8k5Q-u7HpTEhznYRNwHh-6Zpu7mFM3Gaw=s64","userId":"04712707515516063127"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"c4e3d124-25f6-49c2-869b-fd55c4e2d0dc"},"source":["!ls /content/drive/MyDrive/data/NathanGAN/dataset\n","!cd /content/FastGAN-pytorch\n","!ls"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["10.jpg\t14.jpg\t18.jpg\t21.jpg\t25.jpg\t29.jpg\t32.jpg\t6.jpg\n","11.jpg\t15.jpg\t19.jpg\t22.jpg\t26.jpg\t2.jpg\t3.jpg\t7.jpg\n","12.jpg\t16.jpg\t1.jpg\t23.jpg\t27.jpg\t30.jpg\t4.jpg\t8.jpg\n","13.jpg\t17.jpg\t20.jpg\t24.jpg\t28.jpg\t31.jpg\t5.jpg\t9.jpg\n","drive  FastGAN-pytorch\tsample_data\n"]}]},{"cell_type":"markdown","source":["# IMPORTANT: Replace train.py with code below"],"metadata":{"id":"cdZWqS5-UO7r"}},{"cell_type":"markdown","source":["Do this in the FastGAN-pytorch folder"],"metadata":{"id":"F_9coyO_hCjt"}},{"cell_type":"code","source":["from pickle import FALSE\n","import torch\n","from torch import nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data.dataloader import DataLoader\n","from torchvision import transforms\n","from torchvision import utils as vutils\n","import numpy.random as nprand\n","import argparse\n","import random\n","from tqdm import tqdm\n","import os\n","from models import weights_init, Discriminator, Generator\n","from operation import copy_G_params, load_params, get_dir\n","from operation import ImageFolder, InfiniteSamplerWrapper\n","from diffaug import DiffAugment\n","policy = 'color,translation'\n","import lpips\n","percept = lpips.PerceptualLoss(model='net-lin', net='vgg', use_gpu=True)\n","\n","\n","#torch.backends.cudnn.benchmark = True\n","\n","\n","def crop_image_by_part(image, part):\n","    hw = image.shape[2]//2\n","    if part==0:\n","        return image[:,:,:hw,:hw]\n","    if part==1:\n","        return image[:,:,:hw,hw:]\n","    if part==2:\n","        return image[:,:,hw:,:hw]\n","    if part==3:\n","        return image[:,:,hw:,hw:]\n","\n","def train_d(net, data, label=\"real\"):\n","    \"\"\"Train function of discriminator\"\"\"\n","    if label==\"real\":\n","        part = random.randint(0, 3)\n","        pred, [rec_all, rec_small, rec_part] = net(data, label, part=part)\n","        err = F.relu(  torch.rand_like(pred) * 0.2 + 0.8 -  pred).mean() + \\\n","            percept( rec_all, F.interpolate(data, rec_all.shape[2]) ).sum() +\\\n","            percept( rec_small, F.interpolate(data, rec_small.shape[2]) ).sum() +\\\n","            percept( rec_part, F.interpolate(crop_image_by_part(data, part), rec_part.shape[2]) ).sum()\n","        err.backward()\n","        return pred.mean().item(), rec_all, rec_small, rec_part\n","    else:\n","        pred = net(data, label)\n","        err = F.relu( torch.rand_like(pred) * 0.2 + 0.8 + pred).mean()\n","        err.backward()\n","        return pred.mean().item()\n","\n","def seed2vec(seed, batch_size, noise_dim):\n","    return nprand.RandomState(seed).randn(batch_size, noise_dim)\n","\n","def train(args):\n","    delete_old_ckpts = True\n","    data_root = args.path\n","    total_iterations = args.iter\n","    checkpoint = args.ckpt\n","    batch_size = args.batch_size\n","    im_size = args.im_size\n","    ndf = 64\n","    ngf = 64\n","    nz = 256\n","    nlr = 0.0002\n","    nbeta1 = 0.6\n","    use_cuda = True\n","    dataloader_workers = 2\n","    current_iteration = args.start_iter\n","    save_interval = 10\n","    saved_model_folder = '/content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/models'\n","    saved_image_folder = '/content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/images'\n","    \n","    device = torch.device(\"cuda:0\")\n","    if not use_cuda:\n","        device = torch.device(\"cpu\")\n","\n","    transform_list = [\n","            transforms.Resize((int(im_size),int(im_size))),\n","            transforms.RandomHorizontalFlip(),\n","            transforms.ToTensor(),\n","            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n","        ]\n","    trans = transforms.Compose(transform_list)\n","    \n","    if 'lmdb' in data_root:\n","        from operation import MultiResolutionDataset\n","        dataset = MultiResolutionDataset(data_root, trans, 1024)\n","    else:\n","        dataset = ImageFolder(root=data_root, transform=trans)\n","\n","    dataloader = iter(DataLoader(dataset, batch_size=batch_size, shuffle=False, \n","                sampler=InfiniteSamplerWrapper(dataset), num_workers=dataloader_workers, pin_memory=True))\n","    '''\n","    loader = MultiEpochsDataLoader(dataset, batch_size=batch_size, \n","                               shuffle=True, num_workers=dataloader_workers, \n","                               pin_memory=True)\n","    dataloader = CudaDataLoader(loader, 'cuda')\n","    '''\n","    \n","    #from model_s import Generator, Discriminator\n","    netG = Generator(ngf=ngf, nz=nz, im_size=im_size)\n","    netG.apply(weights_init)\n","\n","    netD = Discriminator(ndf=ndf, im_size=im_size)\n","    netD.apply(weights_init)\n","\n","    netG.to(device)\n","    netD.to(device)\n","\n","    avg_param_G = copy_G_params(netG)\n","\n","    fixed_noise = torch.tensor(seed2vec(69420, 8, nz), dtype=torch.float32).to(device)\n","    \n","    optimizerG = optim.Adam(netG.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n","    optimizerD = optim.Adam(netD.parameters(), lr=nlr, betas=(nbeta1, 0.999))\n","\n","    if checkpoint != None:\n","        ckpt = torch.load(checkpoint, map_location='cuda')\n","        netG.load_state_dict(ckpt['g'])\n","        netD.load_state_dict(ckpt['d'])\n","        avg_param_G = ckpt['g_ema']\n","        optimizerG.load_state_dict(ckpt['opt_g'])\n","        optimizerD.load_state_dict(ckpt['opt_d'])\n","        current_iteration = int(checkpoint.split('_')[-1].split('.')[0])\n","        del ckpt\n","    \n","    with tqdm(total=total_iterations - current_iteration, ascii=True, smoothing=0.6) as pbar:\n","        for iteration in range(current_iteration, total_iterations+1, batch_size):\n","            real_image = next(dataloader)\n","            real_image = real_image.to(device)\n","            current_batch_size = real_image.size(0)\n","            noise = torch.Tensor(current_batch_size, nz).normal_(0, 1).to(device)\n","\n","            fake_images = netG(noise)\n","\n","            real_image = DiffAugment(real_image, policy=policy)\n","            fake_images = [DiffAugment(fake, policy=policy) for fake in fake_images]\n","            \n","            ## 2. train Discriminator\n","            netD.zero_grad()\n","\n","            err_dr, rec_img_all, rec_img_small, rec_img_part = train_d(netD, real_image, label=\"real\")\n","            train_d(netD, [fi.detach() for fi in fake_images], label=\"fake\")\n","            optimizerD.step()\n","            \n","            ## 3. train Generator\n","            netG.zero_grad()\n","            pred_g = netD(fake_images, \"fake\")\n","            err_g = -pred_g.mean()\n","\n","            err_g.backward()\n","            optimizerG.step()\n","\n","            for p, avg_p in zip(netG.parameters(), avg_param_G):\n","                avg_p.mul_(0.999).add_(0.001 * p.data)\n","\n","            if iteration % 10000 < batch_size:\n","                print(\"\\nGAN: loss d: %.5f    loss g: %.5f\"%(err_dr, -err_g.item()))\n","\n","            if iteration % (save_interval*500) < batch_size:\n","                backup_para = copy_G_params(netG)\n","                load_params(netG, avg_param_G)\n","                with torch.no_grad():\n","                    vutils.save_image(netG(fixed_noise)[0].add(1).mul(0.5), saved_image_folder+'/%d.jpg'%iteration, nrow=4)\n","                    vutils.save_image( torch.cat([\n","                            F.interpolate(real_image, 128), \n","                            rec_img_all, rec_img_small,\n","                            rec_img_part]).add(1).mul(0.5), saved_image_folder+'/rec_%d.jpg'%iteration )\n","                load_params(netG, backup_para)\n","\n","            if iteration % (save_interval*500) < batch_size or iteration == total_iterations:\n","                backup_para = copy_G_params(netG)\n","                # load_params(netG, avg_param_G)\n","                # torch.save({'g':netG.state_dict(),'d':netD.state_dict()}, saved_model_folder+'/%d.pth'%iteration)\n","                load_params(netG, backup_para)\n","                torch.save({'g':netG.state_dict(),\n","                            'd':netD.state_dict(),\n","                            'g_ema': avg_param_G,\n","                            'opt_g': optimizerG.state_dict(),\n","                            'opt_d': optimizerD.state_dict()}, saved_model_folder+'/all_%d.pth'%iteration)\n","                if delete_old_ckpts:\n","                    model_filenames = os.listdir(saved_model_folder)\n","                    part_model_filenames = []\n","                    all_model_filenames = []\n","                    for file in model_filenames:\n","                        if file == file.split('_')[0]:\n","                            part_model_filenames += [file]\n","                        else:\n","                            all_model_filenames += [file]\n","\n","                    while len(part_model_filenames) > 2:\n","                        os.remove(saved_model_folder + '/' + part_model_filenames[0])\n","                        part_model_filenames.pop(0)\n","\n","                    while len(all_model_filenames) > 2:\n","                        os.remove(saved_model_folder + '/' + all_model_filenames[0])\n","                        all_model_filenames.pop(0)\n","\n","            pbar.update(batch_size)\n","\n","\n","if __name__ == \"__main__\":\n","    parser = argparse.ArgumentParser(description='region gan')\n","    parser.add_argument('--path', type=str, default='/content/drive/MyDrive/data/NathanGAN/dataset/', help='path of resource dataset, should be a folder that has one or many sub image folders inside')\n","    parser.add_argument('--cuda', type=int, default=1, help='index of gpu to use')\n","    parser.add_argument('--name', type=str, default='NathanGAN', help='experiment name')\n","    parser.add_argument('--iter', type=int, default=500000, help='number of iterations')\n","    parser.add_argument('--start_iter', type=int, default=0, help='the iteration to start training')\n","    parser.add_argument('--batch_size', type=int, default=8, help='mini batch number of images')\n","    parser.add_argument('--im_size', type=int, default=1024, help='image resolution')\n","    parser.add_argument('--ckpt', type=str, help='checkpoint weight path if have one')\n","    args = parser.parse_args()\n","\n","    if args.ckpt is None:\n","        dir = '/content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/models/'\n","        ckpt_file = os.listdir(dir)[-1]\n","        args.ckpt = dir + ckpt_file\n","        print('warning: ckpt is defaulting to ' + args.ckpt)\n","    assert os.path.exists(args.ckpt), 'checkpoint path does not exist'\n","\n","    args.start_iter = int(ckpt_file.partition('_')[-1].partition('.')[0])\n","    # args.iter = args.start_iter + 4600\n","\n","    print(args)\n","    train(args)"],"metadata":{"id":"a8rm44ThShq0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Alas! we train"],"metadata":{"id":"yrzjhtqQcIyA"}},{"cell_type":"markdown","source":["Additional arguments can be found in the train.py file. I prefer to change the default within the file itself although that's probably bad practice."],"metadata":{"id":"Ee9nk7IG5pm2"}},{"cell_type":"code","source":["import os\n","\n","checkpointdir = '/content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/models/'\n","latest_ckpt_file = os.listdir(dir)[-1]\n","CHECKPOINT = dir + latest_ckpt_file\n","DATASET = \"/content/drive/MyDrive/data/NathanGAN/dataset\"\n","\n","# Build the command and run it\n","cmd = f\"/usr/bin/python3 /content/FastGAN-pytorch/train.py --ckpt {CHECKPOINT} --path {DATASET}\"\n","!{cmd}"],"metadata":{"id":"H-grfBhc43LV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["... or if you prefer ..."],"metadata":{"id":"fKwJhE3X6KX7"}},{"cell_type":"code","metadata":{"id":"j4g2FUCwG1U_","colab":{"base_uri":"https://localhost:8080/"},"outputId":"46ce175a-6f52-4543-812b-4064476a56fc"},"source":["!/usr/bin/python3 /content/FastGAN-pytorch/train.py "],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Setting up Perceptual loss...\n","Loading model from: /content/FastGAN-pytorch/lpips/weights/v0.1/vgg.pth\n","...[net-lin [vgg]] initialized\n","...Done\n","warning: ckpt is defaulting to /content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/models/all_38000.pth\n","Namespace(batch_size=8, ckpt='/content/drive/MyDrive/data/NathanGAN/train_results/NathanGAN/models/all_38000.pth', cuda=1, im_size=1024, iter=500000, name='NathanGAN', path='/content/drive/MyDrive/data/NathanGAN/dataset/', start_iter=38000)\n","  0% 0/462000 [00:00<?, ?it/s]/usr/local/lib/python3.7/dist-packages/torch/functional.py:445: UserWarning: torch.meshgrid: in an upcoming release, it will be required to pass the indexing argument. (Triggered internally at  ../aten/src/ATen/native/TensorShape.cpp:2157.)\n","  return _VF.meshgrid(tensors, **kwargs)  # type: ignore[attr-defined]\n","  0% 2000/462000 [13:36<51:45:30,  2.47it/s]\n","GAN: loss d: 0.71223    loss g: -2.02596\n","  1% 4152/462000 [28:17<51:49:08,  2.45it/s]"]}]}]}